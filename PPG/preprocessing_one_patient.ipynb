{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import neurokit2 as nk\n",
    "import nolds\n",
    "from scipy import signal\n",
    "import heartpy as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_PPG = 'C:/Users/citioplab/Downloads/TVGH002'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前處理 acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 消除基線飄移\n",
    "def filt_ma(acc):\n",
    "    newlist = [x for x in acc if math.isnan(x) == False]\n",
    "    b, a = signal.butter(3, 0.1, btype=\"highpass\", output=\"ba\")\n",
    "    ma_acc = signal.filtfilt(b, a, newlist)\n",
    "    return ma_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 讀一位病人[02]所有的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_imputation(df, column, filename):\n",
    "    # 向下補值\n",
    "    df[column].replace(0, np.nan, inplace=True)\n",
    "    df[column].fillna(method='ffill', inplace=True)\n",
    "    # 補開頭\n",
    "    df[column].replace(np.nan, filename, inplace=True)\n",
    "    # 統一格式\n",
    "    df[column] = df[column].astype(str).str.rstrip('.0')\n",
    "    df[column] = df[column].str.pad(width=14, side='right', fillchar='0')\n",
    "    df[column] = pd.to_datetime(df[column])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\citioplab\\AppData\\Local\\Temp\\ipykernel_5756\\669521990.py:4: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\citioplab\\AppData\\Local\\Temp\\ipykernel_5756\\669521990.py:4: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\citioplab\\AppData\\Local\\Temp\\ipykernel_5756\\669521990.py:4: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\citioplab\\AppData\\Local\\Temp\\ipykernel_5756\\669521990.py:4: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\citioplab\\AppData\\Local\\Temp\\ipykernel_5756\\669521990.py:4: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\citioplab\\AppData\\Local\\Temp\\ipykernel_5756\\669521990.py:4: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\citioplab\\AppData\\Local\\Temp\\ipykernel_5756\\669521990.py:4: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\citioplab\\AppData\\Local\\Temp\\ipykernel_5756\\669521990.py:4: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\citioplab\\AppData\\Local\\Temp\\ipykernel_5756\\669521990.py:4: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column].fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 讀取資料，並做成dataframe\n",
    "no_list = [\"02\"]\n",
    "day_dict = {}\n",
    "\n",
    "for who in no_list:\n",
    "    # goto = where_PPG + r'\\TVGH0' + str(who) + \"\\\\\"\n",
    "    goto = where_PPG + \"\\\\\"\n",
    "    raw =  os.listdir(goto)\n",
    "    \n",
    "    for raw_data in raw:\n",
    "        new_df = pd.DataFrame(columns=['Measure_time', 'X_acc', 'Y_acc', 'Z_acc'])\n",
    "\n",
    "        if \"raw\" in raw_data.split(\".\")[0]: \n",
    "            filename = raw_data.split(\".\")[0].replace('_raw.xlsx', '')[:14]\n",
    "            df = pd.read_csv(goto + raw_data ,header = None)\n",
    "            df = df.dropna()\n",
    "\n",
    "            # 取出csv中的欄位值\n",
    "            measure_time = np.array(df[0].values.tolist()).T[0]\n",
    "            x_acc = filt_ma(np.array(df[[4]].values.tolist()).T[0]) # 消除基線飄移\n",
    "            y_acc = filt_ma(np.array(df[[5]].values.tolist()).T[0]) # 消除基線飄移\n",
    "            z_acc = filt_ma(np.array(df[[6]].values.tolist()).T[0]) # 消除基線飄移\n",
    "\n",
    "            # 做成dataframe\n",
    "            part_df = pd.DataFrame({'Measure_time': df[0].tolist(), 'X_acc':x_acc, 'Y_acc': y_acc, 'Z_acc': z_acc})\n",
    "            file_start_time = filename[:13] + str((int(filename[13]) - 1))\n",
    "            part_df = time_imputation(part_df, 'Measure_time', file_start_time)\n",
    "            \n",
    "            day_dict[filename] = part_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認每秒不超過64筆資料\n",
    "for data in day_dict.values():\n",
    "    period_counts_df = pd.DataFrame({'Measure_time': data['Measure_time'].value_counts().index, 'Count': data['Measure_time'].value_counts().values})\n",
    "    sorted_counts_df = period_counts_df.sort_values(by='Measure_time').reset_index(drop=True)\n",
    "    if len(sorted_counts_df.loc[sorted_counts_df['Count'] > 64, 'Measure_time']) > 0:\n",
    "        print(sorted_counts_df.loc[sorted_counts_df['Count'] > 64, 'Measure_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 計算SPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_sec_acc_rolling_med(data):\n",
    "    # 取平均改以秒為單位\n",
    "    X_avg = pd.DataFrame(data.groupby('Measure_time')['X_acc'].mean())\n",
    "    Y_avg = pd.DataFrame(data.groupby('Measure_time')['Y_acc'].mean())\n",
    "    Z_avg = pd.DataFrame(data.groupby('Measure_time')['Z_acc'].mean())\n",
    "    df_sec = pd.DataFrame({'X_acc': X_avg['X_acc'], 'Y_acc': Y_avg['Y_acc'], 'Z_acc': Z_avg['Z_acc']})\n",
    "    \n",
    "    # Compute rolling medians for x, y, z coordinates\n",
    "    rolling_medians_x = df_sec['X_acc'].rolling(window=5).median()\n",
    "    rolling_medians_y = df_sec['Y_acc'].rolling(window=5).median()\n",
    "    rolling_medians_z = df_sec['Z_acc'].rolling(window=5).median()\n",
    "\n",
    "    # Combine rolling medians into a new DataFrame\n",
    "    rolling_medians_df = pd.DataFrame({\n",
    "        'rolling_median_x': rolling_medians_x,\n",
    "        'rolling_median_y': rolling_medians_y,\n",
    "        'rolling_median_z': rolling_medians_z\n",
    "    })\n",
    "    rolling_medians_df = rolling_medians_df.dropna()\n",
    "\n",
    "    return rolling_medians_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(acc_x, acc_y, acc_z):\n",
    "    deg = math.atan(acc_x / (math.sqrt(acc_y**2 + acc_z**2)))*180/math.pi\n",
    "    return deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_diff(rolling_medians_df):\n",
    "    rolling_medians_df['angle'] = rolling_medians_df.apply(lambda row: calculate_angle(row['rolling_median_x'], row['rolling_median_y'], row['rolling_median_z']), axis=1)\n",
    "    \n",
    "    # Compute 5 sec rolling average for angles\n",
    "    rolling_avg_angle = pd.DataFrame(rolling_medians_df['angle'].rolling(window=5).mean())\n",
    "    # rolling_avg_angle = rolling_avg_angle.dropna()\n",
    "\n",
    "    # Compute the difference between consecutive angle averages\n",
    "    rolling_avg_angle['angle_diff'] = rolling_avg_angle['angle'].diff()\n",
    "    rolling_avg_angle['angle_diff'] = abs(rolling_avg_angle['angle_diff'])\n",
    "    rolling_avg_angle = rolling_avg_angle.dropna()\n",
    "\n",
    "    # 確認測量時間是連續的(無中斷，2019-04-13 15:36:29是中斷的)\n",
    "    rolling_avg_angle = rolling_avg_angle.reset_index()\n",
    "    rolling_avg_angle['time_diff'] = pd.to_timedelta(rolling_avg_angle['Measure_time'].diff())\n",
    "    filtered_df = rolling_avg_angle[rolling_avg_angle['time_diff'] != pd.Timedelta('0 days 00:00:01')]\n",
    "    # if filtered_df.shape[0] > 1:\n",
    "    #     return \"Time is not continuous\"\n",
    "    \n",
    "    # Compute the 5 minutes rolling median for the angle differences\n",
    "    rolling_median_5min_angle = pd.DataFrame({\n",
    "        'Measure_time': rolling_avg_angle['Measure_time'],\n",
    "        'rolling_median_angle': rolling_avg_angle['angle_diff'].rolling(window=300).median()\n",
    "    })\n",
    "    rolling_median_5min_angle = rolling_median_5min_angle.dropna()\n",
    "    \n",
    "    return rolling_median_5min_angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_detection(angDiff, q, verbose):\n",
    "    # 標註靜止的時間\n",
    "    threshold = angDiff['rolling_median_angle'].quantile(q)\n",
    "    angDiff['still'] = angDiff['rolling_median_angle'].apply(lambda x: 1 if x < threshold else 0)  \n",
    "    if verbose:\n",
    "        print(angDiff['still'].value_counts())\n",
    "        \n",
    "    # 找到所有的blocks\n",
    "    block_start = []\n",
    "    block_end = []\n",
    "    pre_value = 0\n",
    "\n",
    "    for idx, value in enumerate(angDiff['still']):\n",
    "        if pre_value == 0 and value == 1:\n",
    "            block_start.append(angDiff['Measure_time'].iloc[idx])\n",
    "        elif pre_value == 1 and value == 0:\n",
    "            block_end.append(angDiff['Measure_time'].iloc[idx-1])\n",
    "        pre_value = value\n",
    "    block_duration = [block_end[i] - block_start[i] for i in range(len(block_end))]\n",
    "    if verbose:\n",
    "        print(len(block_start), len(block_end), len(block_duration))\n",
    "    blocks_df = pd.DataFrame({'block_start': block_start[:len(block_end)], 'block_end': block_end, 'duration':block_duration})\n",
    "    \n",
    "    # 留下持續超過30分鐘的blocks，並計算time gap\n",
    "    spt_blocks = blocks_df[blocks_df['duration'] > pd.Timedelta('0 days 00:10:00')]\n",
    "    time_gap_list = []\n",
    "    for idx, value in enumerate(spt_blocks['block_end']):\n",
    "        if idx < len(spt_blocks)-1:\n",
    "            time_gap_list.append(spt_blocks['block_start'].iloc[idx+1] - spt_blocks['block_end'].iloc[idx])\n",
    "        else:\n",
    "            time_gap_list.append(np.nan)\n",
    "    spt_blocks['time_gap'] = time_gap_list\n",
    "    return spt_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_blocks_to_SPT(spt_blocks):\n",
    "    # 整併間隔<60min的blocks\n",
    "    SPT_start = 0\n",
    "    SPT_end = 0\n",
    "    SPT_duration = pd.Timedelta('0 days 00:00:00')\n",
    "    temp_start = 0\n",
    "    temp_end = 0\n",
    "    temp_duration = pd.Timedelta('0 days 00:00:00')\n",
    "\n",
    "    for idx, value in enumerate(spt_blocks['time_gap']):\n",
    "\n",
    "        if value < pd.Timedelta('0 days 00:60:00'):\n",
    "            if idx == 0:\n",
    "                temp_start = spt_blocks['block_start'].iloc[idx]\n",
    "            elif spt_blocks['time_gap'].iloc[idx-1] > pd.Timedelta('0 days 00:60:00'):\n",
    "                temp_start = spt_blocks['block_start'].iloc[idx]\n",
    "\n",
    "            temp_end = spt_blocks['block_end'].iloc[idx+1]\n",
    "            temp_duration += spt_blocks['duration'].iloc[idx]\n",
    "\n",
    "        else:\n",
    "            if temp_duration > SPT_duration:\n",
    "                SPT_duration = temp_duration\n",
    "                SPT_start = temp_start\n",
    "                SPT_end = temp_end\n",
    "            temp_duration = pd.Timedelta('0 days 00:00:00')\n",
    "            \n",
    "    return SPT_start, SPT_end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:2019-04-02 03:29:45 ; SPT_start:2019-04-02 10:33:41 ; SPT_end:2019-04-02 14:04:00\n",
      "Date:2019-04-08 18:48:35 ; SPT_start:2019-04-08 20:49:23 ; SPT_end:2019-04-09 02:12:50\n",
      "Date:2019-04-11 16:45:01 ; SPT_start:2019-04-11 23:16:03 ; SPT_end:2019-04-12 05:36:20\n",
      "Date:2019-04-12 15:59:26 ; SPT_start:2019-04-13 00:15:37 ; SPT_end:2019-04-13 07:31:03\n",
      "Date:2019-04-13 15:36:29 ; SPT_start:2019-04-14 00:19:54 ; SPT_end:2019-04-14 08:47:40\n",
      "Date:2019-04-14 15:01:47 ; SPT_start:2019-04-14 23:35:46 ; SPT_end:2019-04-15 05:19:58\n",
      "Date:2019-04-15 16:11:12 ; SPT_start:2019-04-15 20:55:05 ; SPT_end:2019-04-16 01:36:08\n",
      "Date:2019-04-16 15:54:35 ; SPT_start:2019-04-16 18:36:14 ; SPT_end:2019-04-17 00:05:28\n",
      "Date:2019-04-17 18:04:11 ; SPT_start:2019-04-18 04:57:41 ; SPT_end:2019-04-18 13:57:57\n"
     ]
    }
   ],
   "source": [
    "for date in day_dict.keys():\n",
    "    data = day_dict[date]\n",
    "    \n",
    "    rolling_medians_df = five_sec_acc_rolling_med(data)\n",
    "    angDiff = angle_diff(rolling_medians_df)\n",
    "    spt_blocks = block_detection(angDiff, q = 0.55,verbose=False)\n",
    "    SPT_start, SPT_end = turn_blocks_to_SPT(spt_blocks)\n",
    "        \n",
    "    print(f\"Date:{pd.to_datetime(date[:14])} ; SPT_start:{SPT_start} ; SPT_end:{SPT_end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:2019-04-02 03:29:45 ; SPT_start:2019-04-02 10:33:27 ; SPT_end:2019-04-02 14:04:15\n",
      "Date:2019-04-08 18:48:35 ; SPT_start:2019-04-08 20:49:14 ; SPT_end:2019-04-09 02:14:10\n",
      "Date:2019-04-11 16:45:01 ; SPT_start:2019-04-11 23:15:52 ; SPT_end:2019-04-12 05:36:23\n",
      "Date:2019-04-12 15:59:26 ; SPT_start:2019-04-13 00:15:28 ; SPT_end:2019-04-13 07:49:26\n",
      "Date:2019-04-13 15:36:29 ; SPT_start:2019-04-13 23:56:45 ; SPT_end:2019-04-14 08:55:54\n",
      "Date:2019-04-14 15:01:47 ; SPT_start:2019-04-14 23:31:52 ; SPT_end:2019-04-15 05:21:04\n",
      "Date:2019-04-15 16:11:12 ; SPT_start:2019-04-15 20:52:41 ; SPT_end:2019-04-16 01:36:16\n",
      "Date:2019-04-16 15:54:35 ; SPT_start:2019-04-16 18:36:13 ; SPT_end:2019-04-17 00:06:44\n",
      "Date:2019-04-17 18:04:11 ; SPT_start:2019-04-18 04:57:38 ; SPT_end:2019-04-18 13:57:58\n"
     ]
    }
   ],
   "source": [
    "for date in day_dict.keys():\n",
    "    data = day_dict[date]\n",
    "    \n",
    "    rolling_medians_df = five_sec_acc_rolling_med(data)\n",
    "    angDiff = angle_diff(rolling_medians_df)\n",
    "    spt_blocks = block_detection(angDiff, q = 0.6,verbose=False)\n",
    "    SPT_start, SPT_end = turn_blocks_to_SPT(spt_blocks)\n",
    "        \n",
    "    print(f\"Date:{pd.to_datetime(date[:14])} ; SPT_start:{SPT_start} ; SPT_end:{SPT_end}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
