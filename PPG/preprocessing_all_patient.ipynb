{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import neurokit2 as nk\n",
    "import nolds\n",
    "from scipy import signal\n",
    "import heartpy as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_PPG = 'C:/Users/citioplab/聯發科PPG Raw Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前處理 acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 消除基線飄移\n",
    "def filt_ma(acc):\n",
    "    newlist = [x for x in acc if math.isnan(x) == False]\n",
    "    b, a = signal.butter(3, 0.1, btype=\"highpass\", output=\"ba\")\n",
    "    ma_acc = signal.filtfilt(b, a, newlist)\n",
    "    return ma_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 讀所有病人所有的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_imputation(df, column, filename):\n",
    "    # 向下補值\n",
    "    df[column].replace(0, np.nan, inplace=True)\n",
    "    df[column].fillna(method='ffill', inplace=True)\n",
    "    # 補開頭\n",
    "    df[column].replace(np.nan, filename, inplace=True)\n",
    "    # 統一格式\n",
    "    df[column] = df[column].astype(str).str.rstrip('.0')\n",
    "    df[column] = df[column].str.pad(width=14, side='right', fillchar='0')\n",
    "    df[column] = pd.to_datetime(df[column], format='%Y%m%d%H%M%S', errors='coerce')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取資料，並做成dataframe\n",
    "def read_data(where_PPG, patient, verbose):\n",
    "\n",
    "    day_dict = {}\n",
    "\n",
    "    if \"(x)\" not in patient:\n",
    "        goto = where_PPG + \"//\" + str(patient) + \"//\"\n",
    "        raw =  os.listdir(goto)\n",
    "        \n",
    "        for raw_data in raw:\n",
    "            new_df = pd.DataFrame(columns=['Measure_time', 'X_acc', 'Y_acc', 'Z_acc'])\n",
    "\n",
    "            if \"raw\" in raw_data.split(\".\")[0]: \n",
    "                filename = raw_data.split(\".\")[0].replace('_raw.xlsx', '')[:14]\n",
    "                df = pd.read_csv(goto + raw_data ,header = None)\n",
    "                df = df.dropna()\n",
    "\n",
    "                # 取出csv中的欄位值\n",
    "                measure_time = np.array(df[0].values.tolist()).T[0]\n",
    "                x_acc = filt_ma(np.array(df[[4]].values.tolist()).T[0]) # 消除基線飄移\n",
    "                y_acc = filt_ma(np.array(df[[5]].values.tolist()).T[0]) # 消除基線飄移\n",
    "                z_acc = filt_ma(np.array(df[[6]].values.tolist()).T[0]) # 消除基線飄移\n",
    "\n",
    "                # 做成dataframe\n",
    "                part_df = pd.DataFrame({'Measure_time': df[0].tolist(), 'X_acc':x_acc, 'Y_acc': y_acc, 'Z_acc': z_acc})\n",
    "                file_start_time = pd.to_datetime(filename[:14], format='%Y%m%d%H%M%S', errors='coerce') - pd.Timedelta(seconds=1)\n",
    "                part_df = time_imputation(part_df, 'Measure_time', file_start_time)\n",
    "                \n",
    "                day_dict[filename] = part_df\n",
    "        if verbose:\n",
    "            print(f\"{patient} read, length = {day_dict.__len__()}\")\n",
    "    else:\n",
    "        print(f\"{patient} empty\")\n",
    "    return day_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 確認每秒不超過64筆資料\n",
    "# for data in day_dict.values():\n",
    "#     period_counts_df = pd.DataFrame({'Measure_time': data['Measure_time'].value_counts().index, 'Count': data['Measure_time'].value_counts().values})\n",
    "#     sorted_counts_df = period_counts_df.sort_values(by='Measure_time').reset_index(drop=True)\n",
    "#     if len(sorted_counts_df.loc[sorted_counts_df['Count'] > 64, 'Measure_time']) > 0:\n",
    "#         print(sorted_counts_df.loc[sorted_counts_df['Count'] > 64, 'Measure_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 計算SPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_sec_acc_rolling_med(data):\n",
    "    # 取平均改以秒為單位\n",
    "    X_avg = pd.DataFrame(data.groupby('Measure_time')['X_acc'].mean())\n",
    "    Y_avg = pd.DataFrame(data.groupby('Measure_time')['Y_acc'].mean())\n",
    "    Z_avg = pd.DataFrame(data.groupby('Measure_time')['Z_acc'].mean())\n",
    "    df_sec = pd.DataFrame({'X_acc': X_avg['X_acc'], 'Y_acc': Y_avg['Y_acc'], 'Z_acc': Z_avg['Z_acc']})\n",
    "    \n",
    "    # Compute rolling medians for x, y, z coordinates\n",
    "    rolling_medians_x = df_sec['X_acc'].rolling(window=5).median()\n",
    "    rolling_medians_y = df_sec['Y_acc'].rolling(window=5).median()\n",
    "    rolling_medians_z = df_sec['Z_acc'].rolling(window=5).median()\n",
    "\n",
    "    # Combine rolling medians into a new DataFrame\n",
    "    rolling_medians_df = pd.DataFrame({\n",
    "        'rolling_median_x': rolling_medians_x,\n",
    "        'rolling_median_y': rolling_medians_y,\n",
    "        'rolling_median_z': rolling_medians_z\n",
    "    })\n",
    "    rolling_medians_df = rolling_medians_df.dropna()\n",
    "\n",
    "    return rolling_medians_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(acc_x, acc_y, acc_z):\n",
    "    deg = math.atan(acc_x / (math.sqrt(acc_y**2 + acc_z**2)))*180/math.pi\n",
    "    return deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_diff(rolling_medians_df):\n",
    "    rolling_medians_df['angle'] = rolling_medians_df.apply(lambda row: calculate_angle(row['rolling_median_x'], row['rolling_median_y'], row['rolling_median_z']), axis=1)\n",
    "    \n",
    "    # Compute 5 sec rolling average for angles\n",
    "    rolling_avg_angle = pd.DataFrame(rolling_medians_df['angle'].rolling(window=5).mean())\n",
    "    # rolling_avg_angle = rolling_avg_angle.dropna()\n",
    "\n",
    "    # Compute the difference between consecutive angle averages\n",
    "    rolling_avg_angle['angle_diff'] = rolling_avg_angle['angle'].diff()\n",
    "    rolling_avg_angle['angle_diff'] = abs(rolling_avg_angle['angle_diff'])\n",
    "    rolling_avg_angle = rolling_avg_angle.dropna()\n",
    "\n",
    "    # 確認測量時間是連續的(無中斷，2019-04-13 15:36:29是中斷的)\n",
    "    rolling_avg_angle = rolling_avg_angle.reset_index()\n",
    "    rolling_avg_angle['time_diff'] = pd.to_timedelta(rolling_avg_angle['Measure_time'].diff())\n",
    "    filtered_df = rolling_avg_angle[rolling_avg_angle['time_diff'] != pd.Timedelta('0 days 00:00:01')]\n",
    "    # if filtered_df.shape[0] > 1:\n",
    "    #     return \"Time is not continuous\"\n",
    "    \n",
    "    # Compute the 5 minutes rolling median for the angle differences\n",
    "    rolling_median_5min_angle = pd.DataFrame({\n",
    "        'Measure_time': rolling_avg_angle['Measure_time'],\n",
    "        'rolling_median_angle': rolling_avg_angle['angle_diff'].rolling(window=300).median()\n",
    "    })\n",
    "    rolling_median_5min_angle = rolling_median_5min_angle.dropna()\n",
    "    \n",
    "    return rolling_median_5min_angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_detection(angDiff, q, verbose):\n",
    "    # 標註靜止的時間\n",
    "    threshold = angDiff['rolling_median_angle'].quantile(q)\n",
    "    angDiff['still'] = angDiff['rolling_median_angle'].apply(lambda x: 1 if x < threshold else 0)  \n",
    "    if verbose:\n",
    "        print(angDiff['still'].value_counts())\n",
    "        \n",
    "    # 找到所有的blocks\n",
    "    block_start = []\n",
    "    block_end = []\n",
    "    pre_value = 0\n",
    "\n",
    "    for idx, value in enumerate(angDiff['still']):\n",
    "        if pre_value == 0 and value == 1:\n",
    "            block_start.append(angDiff['Measure_time'].iloc[idx])\n",
    "        elif pre_value == 1 and value == 0:\n",
    "            block_end.append(angDiff['Measure_time'].iloc[idx-1])\n",
    "        pre_value = value\n",
    "    block_duration = [block_end[i] - block_start[i] for i in range(len(block_end))]\n",
    "    if verbose:\n",
    "        print(len(block_start), len(block_end), len(block_duration))\n",
    "    blocks_df = pd.DataFrame({'block_start': block_start[:len(block_end)], 'block_end': block_end, 'duration':block_duration})\n",
    "    \n",
    "    # 留下持續超過30分鐘的blocks，並計算time gap\n",
    "    spt_blocks = blocks_df[blocks_df['duration'] > pd.Timedelta('0 days 00:10:00')]\n",
    "    time_gap_list = []\n",
    "    for idx, value in enumerate(spt_blocks['block_end']):\n",
    "        if idx < len(spt_blocks)-1:\n",
    "            time_gap_list.append(spt_blocks['block_start'].iloc[idx+1] - spt_blocks['block_end'].iloc[idx])\n",
    "        else:\n",
    "            time_gap_list.append(np.nan)\n",
    "    spt_blocks['time_gap'] = time_gap_list\n",
    "    return spt_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_blocks_to_SPT(spt_blocks):\n",
    "    # 整併間隔<60min的blocks\n",
    "    SPT_start = 0\n",
    "    SPT_end = 0\n",
    "    SPT_duration = pd.Timedelta('0 days 00:00:00')\n",
    "    temp_start = 0\n",
    "    temp_end = 0\n",
    "    temp_duration = pd.Timedelta('0 days 00:00:00')\n",
    "\n",
    "    for idx, value in enumerate(spt_blocks['time_gap']):\n",
    "\n",
    "        if value < pd.Timedelta('0 days 00:60:00'):\n",
    "            if idx == 0:\n",
    "                temp_start = spt_blocks['block_start'].iloc[idx]\n",
    "            elif spt_blocks['time_gap'].iloc[idx-1] > pd.Timedelta('0 days 00:60:00'):\n",
    "                temp_start = spt_blocks['block_start'].iloc[idx]\n",
    "\n",
    "            temp_end = spt_blocks['block_end'].iloc[idx+1]\n",
    "            temp_duration += spt_blocks['duration'].iloc[idx]\n",
    "\n",
    "        else:\n",
    "            if temp_duration > SPT_duration:\n",
    "                SPT_duration = temp_duration\n",
    "                SPT_start = temp_start\n",
    "                SPT_end = temp_end\n",
    "            temp_duration = pd.Timedelta('0 days 00:00:00')\n",
    "            \n",
    "    return SPT_start, SPT_end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1-42號病患（沒有奇怪缺失值）\n",
    "# patients = os.listdir(where_PPG)[:-8]\n",
    "    \n",
    "# for patient in patients:\n",
    "#     all_data = read_data(where_PPG, patient)\n",
    "#     for date in all_data.keys():\n",
    "#         day_data = all_data[date]\n",
    "        \n",
    "#         rolling_medians_df = five_sec_acc_rolling_med(day_data)\n",
    "#         angDiff = angle_diff(rolling_medians_df)\n",
    "#         spt_blocks = block_detection(angDiff, q = 0.55,verbose=False)\n",
    "#         SPT_start, SPT_end = turn_blocks_to_SPT(spt_blocks)\n",
    "        \n",
    "#         by_patient = pd.DataFrame({'Date':pd.to_datetime(date[:14]), 'SPT_start':SPT_start, 'SPT_end':SPT_end}, index=[0]) \n",
    "#         by_patient.to_csv(f'C:/Users/citioplab/Desktop/github/Lab/PPG/SPT windows/{patient}_SPT.csv', mode='a', header=True, index=False)   \n",
    "            \n",
    "#         # print(f\"Date:{pd.to_datetime(date[:14])} ; SPT_start:{SPT_start} ; SPT_end:{SPT_end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TVGH001 (x) empty\n",
      "TVGH002 done, length = 9\n",
      "TVGH003 done, length = 17\n",
      "TVGH004 (x) empty\n",
      "TVGH005 done, length = 26\n",
      "TVGH006 done, length = 32\n",
      "TVGH007 done, length = 7\n",
      "TVGH008 (x) empty\n",
      "TVGH009 done, length = 12\n",
      "TVGH010 (x) empty\n",
      "TVGH011 (x) empty\n",
      "TVGH012 done, length = 30\n",
      "TVGH013 done, length = 13\n",
      "TVGH014 done, length = 12\n",
      "TVGH015 (x) empty\n",
      "TVGH016 done, length = 14\n",
      "TVGH017 done, length = 9\n",
      "TVGH018 done, length = 18\n",
      "TVGH019 done, length = 17\n",
      "TVGH020 done, length = 10\n",
      "TVGH021 done, length = 9\n",
      "TVGH022 done, length = 19\n",
      "TVGH023 done, length = 12\n",
      "TVGH024 done, length = 13\n",
      "TVGH025 done, length = 18\n",
      "TVGH026 done, length = 10\n",
      "TVGH027 done, length = 9\n",
      "TVGH028 done, length = 11\n",
      "TVGH029 done, length = 16\n",
      "TVGH030 (x) empty\n",
      "TVGH031 done, length = 20\n",
      "TVGH032 done, length = 11\n",
      "TVGH033 done, length = 17\n",
      "TVGH034 done, length = 9\n",
      "TVGH035 (x) empty\n",
      "TVGH036 (x) empty\n",
      "TVGH037 done, length = 11\n",
      "TVGH038 done, length = 9\n",
      "TVGH039 done, length = 6\n",
      "TVGH040 done, length = 10\n",
      "TVGH041 done, length = 14\n",
      "TVGH042 done, length = 8\n",
      "TVGH043 (x) empty\n",
      "TVGH044 is not available, Error tokenizing data. C error: Expected 7 fields in line 2582475, saw 8\n",
      "\n",
      "TVGH045 done, length = 15\n",
      "TVGH046 done, length = 9\n",
      "TVGH047 done, length = 12\n",
      "TVGH048 done, length = 15\n",
      "TVGH049 done, length = 12\n",
      "TVGH050 done, length = 14\n"
     ]
    }
   ],
   "source": [
    "# 所有病患\n",
    "patients = os.listdir(where_PPG)\n",
    "    \n",
    "for patient in patients:\n",
    "    by_patient = pd.DataFrame(columns=['Date', 'SPT_start', 'SPT_end']) \n",
    "\n",
    "    try:\n",
    "        all_data = read_data(where_PPG, patient, verbose=False)\n",
    "        for date in all_data.keys():\n",
    "            day_data = all_data[date]\n",
    "            \n",
    "            rolling_medians_df = five_sec_acc_rolling_med(day_data)\n",
    "            angDiff = angle_diff(rolling_medians_df)\n",
    "            spt_blocks = block_detection(angDiff, q = 0.55,verbose=False)\n",
    "            SPT_start, SPT_end = turn_blocks_to_SPT(spt_blocks)\n",
    "            \n",
    "            new_row = {'Date': pd.to_datetime(date[:14]), 'SPT_start': SPT_start, 'SPT_end': SPT_end}\n",
    "            by_patient.loc[len(by_patient.index)] = new_row\n",
    "\n",
    "        if by_patient.shape[0] > 0:\n",
    "            by_patient.to_csv(f'C:/Users/citioplab/Desktop/github/Lab/PPG/SPT windows/{patient}_SPT.csv', mode='a', header=True, index=False)  \n",
    "            print(f\"{patient} done, length = {by_patient.shape[0]}\") \n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"{patient} is not available, {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
