{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './preprocessed data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = {}\n",
    "impute =  os.listdir(data_path)\n",
    "for method in impute:\n",
    "    goto = data_path + str(method)\n",
    "    method = method.replace(\".csv\",\"\")\n",
    "\n",
    "    if method == 'drop_all_nan':\n",
    "        df_raw = pd.read_csv(goto, index_col=0).reset_index().round(3).iloc[:,1:]\n",
    "        df_raw = df_raw[['7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','0','1','2','3','4','5','6']]\n",
    "\n",
    "    elif method == 'ctgan':\n",
    "        df_train[method] = pd.read_csv(goto, index_col=0)\n",
    "        df_train[method] = df_train[method][['7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','0','1','2','3','4','5','6']]\n",
    "    \n",
    "    else:\n",
    "        df_train[method] = pd.read_csv(goto, index_col=0).reset_index().round(3).iloc[:,3:]\n",
    "        df_train[method] = df_train[method][['7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','0','1','2','3','4','5','6']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ctgan', 'four_avg_drop_nan', 'knn', 'mice', 'three_next_avg_drop_nan', 'three_pre_avg_drop_nan', 'two_avg_drop_nan', 'two_weighted_drop_nan'])\n"
     ]
    }
   ],
   "source": [
    "print(df_train.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {}\n",
    "y = {}\n",
    "\n",
    "X[\"raw\"] = df_raw.iloc[:,:15].values\n",
    "y[\"raw\"] = df_raw.iloc[:,15:].values\n",
    "for method in df_train.keys():\n",
    "    X[method] = df_train[method].iloc[:,:15].values\n",
    "    y[method] = df_train[method].iloc[:,15:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lala7\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, SimpleRNN, LSTM, GRU, Dropout, Dense\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(timesteps, features, verbose):\n",
    "    model = Sequential([\n",
    "        Bidirectional(SimpleRNN(50, activation='relu', input_shape=(timesteps, features), return_sequences=True)),\n",
    "        LSTM(50, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        GRU(50, activation='relu', return_sequences=False),\n",
    "        Dense(9)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    if verbose:\n",
    "        print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(X, y, loss, train_size):\n",
    "    for method in df_train.keys():\n",
    "\n",
    "        # 把一半的完整資料加進去訓練集\n",
    "        X_impute, y_impute = X[method], y[method]\n",
    "        X_train, y_train = np.concatenate((X_impute, X[\"raw\"][:71]), axis=0), np.concatenate((y_impute, y[\"raw\"][:71]), axis=0)\n",
    "        X_test, y_test = X[\"raw\"][71:], y[\"raw\"][71:]\n",
    "\n",
    "        # Reshape input X into a 3D tensor with shape (num_samples, timesteps, features_per_timestep)\n",
    "        X_train_3d = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "        X_test_3d = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "        # Create and train the RNN model\n",
    "        model = create_rnn_model(X_train_3d.shape[1], X_train_3d.shape[2],verbose=False)\n",
    "        model.fit(X_train_3d, y_train, epochs=50, batch_size=16)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        test_loss = model.evaluate(X_test_3d, y_test)\n",
    "        loss[method] = test_loss\n",
    "        train_size[method] = len(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train_raw(X, y, loss, train_size):\n",
    "\n",
    "    # 把一半的完整資料加進去訓練集\n",
    "    X_train, y_train = X[\"raw\"][:71], y[\"raw\"][:71]\n",
    "    X_test, y_test = X[\"raw\"][71:], y[\"raw\"][71:]\n",
    "\n",
    "    # Reshape input X into a 3D tensor with shape (num_samples, timesteps, features_per_timestep)\n",
    "    X_train_3d = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test_3d = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "    # Create and train the RNN model\n",
    "    model = create_rnn_model(X_train_3d.shape[1], X_train_3d.shape[2],verbose=False)\n",
    "    model.fit(X_train_3d, y_train, epochs=50, batch_size=16)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss = model.evaluate(X_test_3d, y_test)\n",
    "    loss[\"raw\"] = test_loss\n",
    "    train_size[\"raw\"] = len(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lala7\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\rnn\\simple_rnn.py:130: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lala7\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\lala7\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "14/14 [==============================] - 7s 19ms/step - loss: 17237.4453\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 17038.5098\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 15745.6230\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 5269.7422\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 1652.9474\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 970.0635\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 838.5027\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 786.0029\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 791.5732\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 778.9796\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 788.0248\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 778.7924\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 787.2961\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 786.7821\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 794.7578\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 790.4901\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 849.1199\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 796.8133\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 797.2181\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 795.4396\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 793.3494\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 785.2937\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 778.3939\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 803.4508\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 785.9234\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 818.4432\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 781.8489\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 770.9434\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 786.3898\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 791.7088\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 805.1033\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 800.4683\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 830.8903\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 781.1207\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 810.6515\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 822.6311\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 773.6281\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 793.9127\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 763.8920\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 813.4690\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 788.5828\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 790.9661\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 787.3533\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 843.6113\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 790.5741\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 779.9854\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 773.5970\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 774.2078\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 787.9401\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 810.8936\n",
      "3/3 [==============================] - 2s 24ms/step - loss: 437.6818\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 20s 29ms/step - loss: 9659.8584\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 2s 23ms/step - loss: 399.0899\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 375.8310\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 2s 23ms/step - loss: 355.3710\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 395.1996\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 2s 27ms/step - loss: 364.4156\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 2s 23ms/step - loss: 356.5967\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 367.0267\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 370.3715\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 353.7009\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 353.6505\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 373.0725\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 386.2105\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 356.8013\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 344.5686\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 365.7039\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 365.7495\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 333.4676\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 339.1933\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 339.3761\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 3s 31ms/step - loss: 291.3460\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 246.7806\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 220.7754\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 3s 36ms/step - loss: 229.7563\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 211.5244\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 3s 30ms/step - loss: 234.7547\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 3s 35ms/step - loss: 231.9612\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 203.2049\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 194.1320\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 2s 27ms/step - loss: 198.4023\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 3s 38ms/step - loss: 194.5140\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 188.4076\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 187.0180\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 190.7094\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 173.5082\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 3s 34ms/step - loss: 178.3300\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 2s 27ms/step - loss: 196.2986\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 189.5529\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 170.8992\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 198.0603\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 2s 27ms/step - loss: 169.8645\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 171.3893\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 179.1006\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 2s 27ms/step - loss: 174.2853\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 2s 27ms/step - loss: 168.8889\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 165.8285\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 2s 27ms/step - loss: 162.7829\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 168.9746\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 2s 27ms/step - loss: 166.5470\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 4s 43ms/step - loss: 167.5436\n",
      "3/3 [==============================] - 3s 37ms/step - loss: 159.9866\n",
      "Epoch 1/50\n",
      "96/96 [==============================] - 20s 29ms/step - loss: 6984.2588\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 2s 24ms/step - loss: 338.2805\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 2s 23ms/step - loss: 332.7939\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 3s 26ms/step - loss: 336.1672\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 338.5110\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 2s 24ms/step - loss: 328.7815\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 329.9916\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 338.0920\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 2s 26ms/step - loss: 330.3005\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 325.6140\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 323.3125\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 2s 26ms/step - loss: 323.1683\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 2s 23ms/step - loss: 330.4678\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 2s 24ms/step - loss: 349.6811\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 2s 23ms/step - loss: 327.6454\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 2s 26ms/step - loss: 354.3688\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 325.1356\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 2s 24ms/step - loss: 332.7951\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 2s 24ms/step - loss: 340.4744\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 2s 24ms/step - loss: 326.3904\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 2s 24ms/step - loss: 318.9801\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 3s 31ms/step - loss: 336.0723\n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 2s 24ms/step - loss: 325.7840\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 2s 24ms/step - loss: 332.5984\n",
      "Epoch 25/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 345.4321\n",
      "Epoch 26/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 332.0880\n",
      "Epoch 27/50\n",
      "96/96 [==============================] - 2s 23ms/step - loss: 334.4175\n",
      "Epoch 28/50\n",
      "96/96 [==============================] - 3s 31ms/step - loss: 335.5754\n",
      "Epoch 29/50\n",
      "96/96 [==============================] - 3s 31ms/step - loss: 328.5175\n",
      "Epoch 30/50\n",
      "96/96 [==============================] - 2s 24ms/step - loss: 333.3014\n",
      "Epoch 31/50\n",
      "96/96 [==============================] - 2s 26ms/step - loss: 327.3736\n",
      "Epoch 32/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 327.0829\n",
      "Epoch 33/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 338.9078\n",
      "Epoch 34/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 338.1705\n",
      "Epoch 35/50\n",
      "96/96 [==============================] - 3s 31ms/step - loss: 347.9014\n",
      "Epoch 36/50\n",
      "96/96 [==============================] - 2s 24ms/step - loss: 318.5437\n",
      "Epoch 37/50\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 343.4663\n",
      "Epoch 38/50\n",
      "96/96 [==============================] - 3s 35ms/step - loss: 335.1300\n",
      "Epoch 39/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 321.3570\n",
      "Epoch 40/50\n",
      "96/96 [==============================] - 2s 26ms/step - loss: 325.5915\n",
      "Epoch 41/50\n",
      "96/96 [==============================] - 3s 27ms/step - loss: 327.2461\n",
      "Epoch 42/50\n",
      "96/96 [==============================] - 2s 26ms/step - loss: 323.9840\n",
      "Epoch 43/50\n",
      "96/96 [==============================] - 3s 27ms/step - loss: 310.3746\n",
      "Epoch 44/50\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 324.6496\n",
      "Epoch 45/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 307.3904\n",
      "Epoch 46/50\n",
      "96/96 [==============================] - 2s 26ms/step - loss: 311.9135\n",
      "Epoch 47/50\n",
      "96/96 [==============================] - 3s 27ms/step - loss: 350.3336\n",
      "Epoch 48/50\n",
      "96/96 [==============================] - 3s 27ms/step - loss: 323.2156\n",
      "Epoch 49/50\n",
      "96/96 [==============================] - 3s 27ms/step - loss: 324.0052\n",
      "Epoch 50/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 342.6679\n",
      "3/3 [==============================] - 4s 21ms/step - loss: 360.2276\n",
      "Epoch 1/50\n",
      "96/96 [==============================] - 21s 29ms/step - loss: 6168.6704\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 3s 26ms/step - loss: 343.8219\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 3s 27ms/step - loss: 332.4517\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 2s 24ms/step - loss: 323.1764\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 323.4633\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 352.5310\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 2s 26ms/step - loss: 342.9962\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 4s 45ms/step - loss: 344.7578\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 355.0187\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 329.6765\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 2s 24ms/step - loss: 327.5966\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 2s 24ms/step - loss: 343.5076\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 2s 24ms/step - loss: 332.1913\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 4s 37ms/step - loss: 331.7512\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 341.1691\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 2s 24ms/step - loss: 320.6172\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 2s 26ms/step - loss: 320.6926\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 3s 32ms/step - loss: 337.1792\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 3s 31ms/step - loss: 336.0312\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 338.0264\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 331.5056\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 3s 27ms/step - loss: 333.1426\n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 316.8206\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 2s 26ms/step - loss: 323.8269\n",
      "Epoch 25/50\n",
      "96/96 [==============================] - 3s 26ms/step - loss: 376.9585\n",
      "Epoch 26/50\n",
      "96/96 [==============================] - 3s 27ms/step - loss: 327.1383\n",
      "Epoch 27/50\n",
      "96/96 [==============================] - 2s 24ms/step - loss: 322.7190\n",
      "Epoch 28/50\n",
      "96/96 [==============================] - 2s 26ms/step - loss: 323.5461\n",
      "Epoch 29/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 338.3580\n",
      "Epoch 30/50\n",
      "96/96 [==============================] - 2s 26ms/step - loss: 322.0972\n",
      "Epoch 31/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 323.7668\n",
      "Epoch 32/50\n",
      "96/96 [==============================] - 2s 24ms/step - loss: 322.2059\n",
      "Epoch 33/50\n",
      "96/96 [==============================] - 2s 24ms/step - loss: 322.4141\n",
      "Epoch 34/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 321.2459\n",
      "Epoch 35/50\n",
      "96/96 [==============================] - 3s 27ms/step - loss: 325.8690\n",
      "Epoch 36/50\n",
      "96/96 [==============================] - 2s 26ms/step - loss: 320.4918\n",
      "Epoch 37/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 330.7756\n",
      "Epoch 38/50\n",
      "96/96 [==============================] - 3s 26ms/step - loss: 346.0255\n",
      "Epoch 39/50\n",
      "96/96 [==============================] - 3s 26ms/step - loss: 319.1086\n",
      "Epoch 40/50\n",
      "96/96 [==============================] - 3s 34ms/step - loss: 326.8715\n",
      "Epoch 41/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 337.3436\n",
      "Epoch 42/50\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 322.8583\n",
      "Epoch 43/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 316.8974\n",
      "Epoch 44/50\n",
      "96/96 [==============================] - 3s 27ms/step - loss: 316.2438\n",
      "Epoch 45/50\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 328.7533\n",
      "Epoch 46/50\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 343.9342\n",
      "Epoch 47/50\n",
      "96/96 [==============================] - 3s 33ms/step - loss: 323.6048\n",
      "Epoch 48/50\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 327.6854\n",
      "Epoch 49/50\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 343.8419\n",
      "Epoch 50/50\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 336.6743\n",
      "3/3 [==============================] - 3s 36ms/step - loss: 356.1041\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 19s 27ms/step - loss: 6950.3218\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 376.2607\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 3s 30ms/step - loss: 409.4308\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 402.8316\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 2s 27ms/step - loss: 384.0828\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 375.0143\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 359.0381\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 364.7458\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 2s 28ms/step - loss: 368.9142\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 2s 29ms/step - loss: 360.6379\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 2s 28ms/step - loss: 386.7189\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 371.8522\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 369.3548\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 2s 27ms/step - loss: 371.6603\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 361.7528\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 2s 27ms/step - loss: 367.6269\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 368.4541\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 360.9377\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 2s 27ms/step - loss: 362.5848\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 2s 27ms/step - loss: 359.6948\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 355.9139\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 2s 27ms/step - loss: 355.3165\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 3s 32ms/step - loss: 358.7925\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 358.2860\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 2s 27ms/step - loss: 369.0975\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 3s 33ms/step - loss: 373.0701\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 388.4894\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 376.4561\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 368.8755\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 369.8072\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 363.8606\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 372.8601\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 379.6549\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 3s 34ms/step - loss: 380.7348\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 370.6568\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 350.3724\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 2s 27ms/step - loss: 385.8633\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 2s 28ms/step - loss: 365.8688\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 365.1858\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 351.1505\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 361.2082\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 354.3260\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 357.0958\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 364.8702\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 355.0470\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 367.0389\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 367.0170\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 2s 28ms/step - loss: 378.9041\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 2s 28ms/step - loss: 364.6644\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 3s 33ms/step - loss: 356.4043\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000014C90F72170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 3s 41ms/step - loss: 369.0331\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 25s 36ms/step - loss: 6813.0347\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 3s 30ms/step - loss: 367.6590\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 381.7274\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 361.3764\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 350.6077\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 354.8781\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 341.7821\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 359.3569\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 379.1267\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 363.3743\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 349.0230\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 361.5969\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 348.6405\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 383.6297\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 2s 27ms/step - loss: 353.8380\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 351.5155\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 355.0599\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 338.9885\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 2s 27ms/step - loss: 341.7660\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 363.2192\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 355.6067\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 370.1961\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 330.6598\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 320.3762\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 315.7817\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 306.4636\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 269.7805\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 220.6147\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 228.1208\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 219.0611\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 209.6727\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 199.0422\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 203.3259\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 203.5358\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 199.6519\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 200.2833\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 225.6152\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 204.9892\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 203.7746\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 2s 27ms/step - loss: 183.9489\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 189.4878\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 191.1444\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 174.1409\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 2s 27ms/step - loss: 175.2966\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 215.5561\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 182.3395\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 173.3859\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 2s 27ms/step - loss: 172.9039\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 3s 39ms/step - loss: 175.0490\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 3s 35ms/step - loss: 185.4530\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000014C95C05A20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 2s 23ms/step - loss: 310.2837\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 20s 31ms/step - loss: 6661.0859\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 369.8965\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 393.6421\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 2s 28ms/step - loss: 370.0681\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 367.1917\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 376.7716\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 401.1866\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 370.9465\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 355.1171\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 375.7536\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 357.4915\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 3s 33ms/step - loss: 361.6428\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 362.2502\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 374.5060\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 367.2038\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 2s 28ms/step - loss: 361.0276\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 2s 30ms/step - loss: 334.2536\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 280.6111\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 247.3362\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 247.8913\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 227.5101\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 230.6991\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 224.3198\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 218.1670\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 195.1602\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 195.7989\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 198.8242\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 201.1431\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 192.0916\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 185.3242\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 195.0734\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 2s 27ms/step - loss: 192.2819\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 209.3218\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 193.6280\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 210.2914\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 195.8946\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 2s 27ms/step - loss: 194.1620\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 187.9843\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 201.7854\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 214.1833\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 181.2474\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 189.4417\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 2s 27ms/step - loss: 192.4119\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 174.5403\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 188.2855\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 184.7199\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 178.9247\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 179.3227\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 194.1352\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 187.7890\n",
      "3/3 [==============================] - 2s 12ms/step - loss: 153.3966\n",
      "Epoch 1/50\n",
      "38/38 [==============================] - 18s 32ms/step - loss: 13744.1006\n",
      "Epoch 2/50\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 2922.8342\n",
      "Epoch 3/50\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 347.7840\n",
      "Epoch 4/50\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 360.9155\n",
      "Epoch 5/50\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 351.2608\n",
      "Epoch 6/50\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 334.4821\n",
      "Epoch 7/50\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 335.2445\n",
      "Epoch 8/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 363.6289\n",
      "Epoch 9/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 342.2422\n",
      "Epoch 10/50\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 334.0722\n",
      "Epoch 11/50\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 350.2952\n",
      "Epoch 12/50\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 348.2446\n",
      "Epoch 13/50\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 387.6093\n",
      "Epoch 14/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 344.3548\n",
      "Epoch 15/50\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 348.8005\n",
      "Epoch 16/50\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 361.0845\n",
      "Epoch 17/50\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 356.3346\n",
      "Epoch 18/50\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 393.6178\n",
      "Epoch 19/50\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 372.4345\n",
      "Epoch 20/50\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 398.8169\n",
      "Epoch 21/50\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 352.7520\n",
      "Epoch 22/50\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 338.3570\n",
      "Epoch 23/50\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 364.1146\n",
      "Epoch 24/50\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 334.3624\n",
      "Epoch 25/50\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 349.5799\n",
      "Epoch 26/50\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 352.7232\n",
      "Epoch 27/50\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 345.7514\n",
      "Epoch 28/50\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 329.7900\n",
      "Epoch 29/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 334.5338\n",
      "Epoch 30/50\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 347.8447\n",
      "Epoch 31/50\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 354.6008\n",
      "Epoch 32/50\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 362.9765\n",
      "Epoch 33/50\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 392.0030\n",
      "Epoch 34/50\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 354.6599\n",
      "Epoch 35/50\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 353.9749\n",
      "Epoch 36/50\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 358.9025\n",
      "Epoch 37/50\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 369.9210\n",
      "Epoch 38/50\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 351.9047\n",
      "Epoch 39/50\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 333.4087\n",
      "Epoch 40/50\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 335.3170\n",
      "Epoch 41/50\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 357.0310\n",
      "Epoch 42/50\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 333.1330\n",
      "Epoch 43/50\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 338.9957\n",
      "Epoch 44/50\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 345.2734\n",
      "Epoch 45/50\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 384.6158\n",
      "Epoch 46/50\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 347.4509\n",
      "Epoch 47/50\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 331.8766\n",
      "Epoch 48/50\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 330.0247\n",
      "Epoch 49/50\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 327.1545\n",
      "Epoch 50/50\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 320.8333\n",
      "3/3 [==============================] - 3s 18ms/step - loss: 328.3556\n"
     ]
    }
   ],
   "source": [
    "loss = {}\n",
    "train_size = {}\n",
    "model_train(X, y, loss, train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 16s 23ms/step - loss: 14602.7900\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14549.8105\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14522.7305\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14494.2988\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14460.7539\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14415.5791\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14338.6865\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14210.2529\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13955.5830\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13369.5166\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11882.8867\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7160.0903\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3457.6306\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 2236.9670\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1374.9517\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1038.9056\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 687.1448\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 504.6323\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 459.9634\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 380.6669\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 365.2882\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 376.1430\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 350.1246\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 341.8204\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 338.7186\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 341.3001\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 325.6565\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 334.2919\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 363.1928\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 329.0694\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 325.8864\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 354.1726\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 320.1086\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 332.2940\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 370.8273\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 329.5505\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 361.4600\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 345.4059\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 358.8589\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 369.6564\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 366.9746\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 414.0977\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 399.3821\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 381.5522\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 375.2098\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 339.5274\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 367.7787\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 354.4186\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 337.3742\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 330.1890\n",
      "3/3 [==============================] - 2s 25ms/step - loss: 353.9845\n"
     ]
    }
   ],
   "source": [
    "model_train_raw(X, y, loss, train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ctgan', 'four_avg_drop_nan', 'knn', 'mice', 'three_next_avg_drop_nan', 'three_pre_avg_drop_nan', 'two_avg_drop_nan', 'two_weighted_drop_nan', 'raw'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ctgan': 437.6817932128906,\n",
       " 'four_avg_drop_nan': 159.98655700683594,\n",
       " 'knn': 360.2275695800781,\n",
       " 'mice': 356.1040954589844,\n",
       " 'three_next_avg_drop_nan': 369.0331115722656,\n",
       " 'three_pre_avg_drop_nan': 310.2837219238281,\n",
       " 'two_avg_drop_nan': 153.39662170410156,\n",
       " 'two_weighted_drop_nan': 328.3555908203125,\n",
       " 'raw': 353.9844970703125}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ctgan': 213,\n",
       " 'four_avg_drop_nan': 1357,\n",
       " 'knn': 1530,\n",
       " 'mice': 1530,\n",
       " 'three_next_avg_drop_nan': 1333,\n",
       " 'three_pre_avg_drop_nan': 1356,\n",
       " 'two_avg_drop_nan': 1330,\n",
       " 'two_weighted_drop_nan': 597,\n",
       " 'raw': 71}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_rows = 6\n",
    "# num_cols = 5\n",
    "# fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 8))\n",
    "# axes = axes.flatten() # for easier indexing\n",
    "\n",
    "# predictions = best_model.predict(best_X_test)\n",
    "\n",
    "# # Loop through the predictions and actual values\n",
    "# for i in range(len(X_test)):\n",
    "#     ax = axes[i]\n",
    "#     ax.plot(predictions[i].tolist(), label='Predictions')\n",
    "\n",
    "#     # Plot actual values\n",
    "#     ax.plot(best_y_test[i].tolist(), label='Actual Values')\n",
    "\n",
    "#     # Customize the subplot\n",
    "#     ax.set_title(f'Row {best_test_index[i]}')\n",
    "#     ax.set_xlabel('Timestep')\n",
    "#     ax.set_ylabel('Value')\n",
    "#     # ax.legend()\n",
    "\n",
    "# # Use tight layout to ensure proper spacing\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Show or save the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 計算 bp>125 的個數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def nighttime_hpt_count(y, lst):\n",
    "#     for i in range(len(y)):\n",
    "#         lst.append(sum(1 if k>125 else 0 for k in y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_count = []\n",
    "# true_count = []\n",
    "# nighttime_hpt_count(predictions, pred_count)\n",
    "# nighttime_hpt_count(best_y_test, true_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "# mse = mean_squared_error(pred_count, true_count)\n",
    "# print(f'Mean Squared Error: {mse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
